{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import itertools as it\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"Data/final_data_with_mean_encoding.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Lists of features by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identifiers\n",
    "identifiers = ['card_id','train_or_test','first_active_month']\n",
    "\n",
    "# Target\n",
    "target = 'target'\n",
    "\n",
    "# Features from original Train/Test.csv\n",
    "features_train_csv = ['feature_1','feature_2','feature_3','year','month','months_to_2018_02']\n",
    "\n",
    "# Features from all_transactions_merchants_groupby_cards\n",
    "features_transactions = [\n",
    "'month_lag__mean','month_lag__std','month_lag__min','month_lag__max','month_lag__range',\n",
    "'purchase_date__range','purchase_date__days_diff_next_purchase_mean',\n",
    "'purchase_date__days_diff_next_purchase_std','purchase_date_year__mean','purchase_date_year__std',\n",
    "'purchase_date_year__min','purchase_date_year__max','purchase_date_year__range',\n",
    "'purchase_date_month__mean','purchase_date_month__std','purchase_date_month__min',\n",
    "'purchase_date_month__max','purchase_date_month__range','purchase_date_day__mean',\n",
    "'purchase_date_day__std','purchase_date_day__min','purchase_date_day__max','purchase_date_day__range',\n",
    "'purchase_date_hour__mean','purchase_date_hour__std','purchase_date_hour__min','purchase_date_hour__max',\n",
    "'purchase_date_hour__range','purchase_date_days_to_2018_02__mean','purchase_date_days_to_2018_02__std',\n",
    "'purchase_date_days_to_2018_02__min','purchase_date_days_to_2018_02__max',\n",
    "'purchase_date_days_to_2018_02__range','authorized_flag_N__mean','authorized_flag_N__var',\n",
    "'authorized_flag_Y__mean','authorized_flag_Y__var','authorized_flag_-9999__mean',\n",
    "'authorized_flag_-9999__var','category_3_A__mean','category_3_A__var','category_3_B__mean',\n",
    "'category_3_B__var','category_3_C__mean','category_3_C__var','category_3_-9999__mean',\n",
    "'category_3_-9999__var','installments__mean','installments__std','installments__min','installments__max',\n",
    "'installments__range','category_1_N__mean','category_1_N__var','category_1_Y__mean','category_1_Y__var',\n",
    "'category_1_-9999__mean','category_1_-9999__var','merchant_category_id__nunique',\n",
    "'merchant_category_id__mode','subsector_id__nunique','subsector_id__mode','merchant_id__nunique',\n",
    "'merchant_id__mode','purchase_amount__mean','purchase_amount__std','purchase_amount__min',\n",
    "'purchase_amount__max','purchase_amount__range','city_id__nunique','city_id__mode','state_id__nunique',\n",
    "'state_id__mode','category_2_1__mean','category_2_1__var','category_2_2__mean','category_2_2__var',\n",
    "'category_2_3__mean','category_2_3__var','category_2_4__mean','category_2_4__var','category_2_5__mean',\n",
    "'category_2_5__var','category_2_-9999__mean','category_2_-9999__var',\n",
    "'merchant_group_id_merchants__nunique','merchant_group_id_merchants__mode',\n",
    "'merchant_category_id_merchants__nunique','merchant_category_id_merchants__mode',\n",
    "'subsector_id_merchants__nunique','subsector_id_merchants__mode','numerical_1_merchants__mean',\n",
    "'numerical_1_merchants__std','numerical_1_merchants__min','numerical_1_merchants__max',\n",
    "'numerical_1_merchants__range','numerical_2_merchants__mean','numerical_2_merchants__std',\n",
    "'numerical_2_merchants__min','numerical_2_merchants__max','numerical_2_merchants__range',\n",
    "'category_1_merchants_N__mean','category_1_merchants_N__var','category_1_merchants_Y__mean',\n",
    "'category_1_merchants_Y__var','category_1_merchants_-9999__mean','category_1_merchants_-9999__var',\n",
    "'most_recent_sales_range_merchants_A__mean','most_recent_sales_range_merchants_A__var',\n",
    "'most_recent_sales_range_merchants_B__mean','most_recent_sales_range_merchants_B__var',\n",
    "'most_recent_sales_range_merchants_C__mean','most_recent_sales_range_merchants_C__var',\n",
    "'most_recent_sales_range_merchants_D__mean','most_recent_sales_range_merchants_D__var',\n",
    "'most_recent_sales_range_merchants_E__mean','most_recent_sales_range_merchants_E__var',\n",
    "'most_recent_sales_range_merchants_-9999__mean','most_recent_sales_range_merchants_-9999__var',\n",
    "'most_recent_purchases_range_merchants_A__mean','most_recent_purchases_range_merchants_A__var',\n",
    "'most_recent_purchases_range_merchants_B__mean','most_recent_purchases_range_merchants_B__var',\n",
    "'most_recent_purchases_range_merchants_C__mean','most_recent_purchases_range_merchants_C__var',\n",
    "'most_recent_purchases_range_merchants_D__mean','most_recent_purchases_range_merchants_D__var',\n",
    "'most_recent_purchases_range_merchants_E__mean','most_recent_purchases_range_merchants_E__var',\n",
    "'most_recent_purchases_range_merchants_-9999__mean','most_recent_purchases_range_merchants_-9999__var',\n",
    "'avg_sales_lag3_merchants__mean','avg_sales_lag3_merchants__std','avg_sales_lag3_merchants__min',\n",
    "'avg_sales_lag3_merchants__max','avg_sales_lag3_merchants__range','avg_purchases_lag3_merchants__mean',\n",
    "'avg_purchases_lag3_merchants__std','avg_purchases_lag3_merchants__min',\n",
    "'avg_purchases_lag3_merchants__max','avg_purchases_lag3_merchants__range',\n",
    "'active_months_lag3_merchants__mean','active_months_lag3_merchants__std',\n",
    "'active_months_lag3_merchants__min','active_months_lag3_merchants__max',\n",
    "'active_months_lag3_merchants__range','avg_sales_lag6_merchants__mean','avg_sales_lag6_merchants__std',\n",
    "'avg_sales_lag6_merchants__min','avg_sales_lag6_merchants__max','avg_sales_lag6_merchants__range',\n",
    "'avg_purchases_lag6_merchants__mean','avg_purchases_lag6_merchants__std',\n",
    "'avg_purchases_lag6_merchants__min','avg_purchases_lag6_merchants__max',\n",
    "'avg_purchases_lag6_merchants__range','active_months_lag6_merchants__mean',\n",
    "'active_months_lag6_merchants__std','active_months_lag6_merchants__min',\n",
    "'active_months_lag6_merchants__max','active_months_lag6_merchants__range',\n",
    "'avg_sales_lag12_merchants__mean','avg_sales_lag12_merchants__std','avg_sales_lag12_merchants__min',\n",
    "'avg_sales_lag12_merchants__max','avg_sales_lag12_merchants__range',\n",
    "'avg_purchases_lag12_merchants__mean','avg_purchases_lag12_merchants__std',\n",
    "'avg_purchases_lag12_merchants__min','avg_purchases_lag12_merchants__max',\n",
    "'avg_purchases_lag12_merchants__range','active_months_lag12_merchants__mean',\n",
    "'active_months_lag12_merchants__std','active_months_lag12_merchants__min',\n",
    "'active_months_lag12_merchants__max','active_months_lag12_merchants__range','category_4_merchants_N__mean',\n",
    "'category_4_merchants_N__var','category_4_merchants_Y__mean','category_4_merchants_Y__var',\n",
    "'category_4_merchants_-9999__mean','category_4_merchants_-9999__var','city_id_merchants__nunique',\n",
    "'city_id_merchants__mode','state_id_merchants__nunique','state_id_merchants__mode',\n",
    "'category_2_merchants_1__mean','category_2_merchants_1__var','category_2_merchants_2__mean',\n",
    "'category_2_merchants_2__var','category_2_merchants_3__mean','category_2_merchants_3__var',\n",
    "'category_2_merchants_4__mean','category_2_merchants_4__var','category_2_merchants_5__mean',\n",
    "'category_2_merchants_5__var','category_2_merchants_-9999__mean','category_2_merchants_-9999__var']\n",
    "\n",
    "# Features from mean_encoding_all_transactions_merchants_groupby_card\n",
    "features_mean_encoding = [\n",
    "    'authorized_flag__mean_encoded','category_3__mean_encoded','category_1__mean_encoded',\n",
    "    'merchant_category_id__mean_encoded','subsector_id__mean_encoded',\n",
    "    'merchant_id__mean_encoded','city_id__mean_encoded','state_id__mean_encoded',\n",
    "    'category_2__mean_encoded','merchant_group_id_merchants__mean_encoded',\n",
    "    'merchant_category_id_merchants__mean_encoded','subsector_id_merchants__mean_encoded',\n",
    "    'category_1_merchants__mean_encoded','most_recent_sales_range_merchants__mean_encoded',\n",
    "    'most_recent_purchases_range_merchants__mean_encoded','category_4_merchants__mean_encoded',\n",
    "    'city_id_merchants__mean_encoded','state_id_merchants__mean_encoded',\n",
    "    'category_2_merchants__mean_encoded']\n",
    "\n",
    "# Features with 1 unique value that should be removed\n",
    "features_1_unique = [\n",
    "    \"purchase_date_year__min\",\"authorized_flag_-9999__mean\",\"authorized_flag_-9999__var\",\n",
    "    \"category_1_-9999__mean\",\"category_1_-9999__var\",\"active_months_lag3_merchants__max\",\n",
    "    \"active_months_lag6_merchants__max\"]\n",
    "\n",
    "# Features mode of IDs\n",
    "features_numeric_IDs_mode = [\n",
    "    'merchant_category_id__mode','subsector_id__mode','city_id__mode',\n",
    "    'state_id__mode','merchant_group_id_merchants__mode','merchant_category_id_merchants__mode',\n",
    "    'subsector_id_merchants__mode','city_id_merchants__mode','state_id_merchants__mode']\n",
    "\n",
    "features_categorical_IDs_mode = ['merchant_id__mode']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For linear models data must be normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will normalize numerical features, excluding the target and the mode of features IDs (which can be integer). *Note*: We will normalize all dataset (Train & Test) together but we could do it on Train and then apply the normalization on Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(data,normalization_type='zscore',features_to_exclude=[]):\n",
    "    df = data.copy()\n",
    "    normalization = {}\n",
    "    normalization_types = [\"int\",\"float\",\"int64\",\"float64\",\"int32\",\"float32\"]\n",
    "    for col in df.columns:\n",
    "        if data[col].dtype in normalization_types and col not in features_to_exclude:\n",
    "            if(normalization_type == 'minmax'):\n",
    "                Min = df[col].min()\n",
    "                Max = df[col].max()\n",
    "                Dif = Max-Min\n",
    "                df[col] = df[col].apply(lambda x: (x-Min)/(Dif))\n",
    "                normalization[col] = ('minmax',Min,Max)\n",
    "            elif(normalization_type == 'zscore'):\n",
    "                Mean = df[col].mean()\n",
    "                Std = df[col].std()\n",
    "                df[col] = df[col].apply(lambda x: (x-Mean)/(Std))\n",
    "                normalization[col] = ('zscore',Mean,Std)\n",
    "    return(df,normalization)\n",
    "\n",
    "features_to_exclude = [target]+features_numeric_IDs_mode+features_categorical_IDs_mode\n",
    "data,normalization = normalization(data,'zscore',features_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select features for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will exclude features with 1 unique value and all mode of ID features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((features_train_csv,features_transactions,features_mean_encoding))\n",
    "features = [col for col in features if col not in features_1_unique+features_categorical_IDs_mode+\\\n",
    "            features_numeric_IDs_mode]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Target metric: RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = lambda predictions,target: np.mean((predictions-target)**2)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Split Train into 2 validation folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First separate Train & Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.loc[data[\"train_or_test\"]==\"train\",:]\n",
    "test = data.loc[data[\"train_or_test\"]==\"test\",:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then split Train into 2 validation folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folds(data,k=2,seed=1):\n",
    "    np.random.seed(seed)\n",
    "    data = data.iloc[np.random.permutation(data.index),:]\n",
    "    data_folds_list = [data.iloc[int(data.shape[0]*i/k):int(data.shape[0]*(i+1)/k),:] for i in range(k)]\n",
    "    return(data_folds_list)\n",
    "\n",
    "k = 2\n",
    "train_folds_list = folds(train,k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Validation with grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define all parameters combinations for grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LR': LinearRegression,\n",
    "}\n",
    "\n",
    "parameters_names = {\n",
    "    'LR': ['fit_intercept','normalize','n_jobs'],\n",
    "}\n",
    "\n",
    "parameters_values = {\n",
    "    # LR: fit_intercept, normalize, n_jobs\n",
    "    'LR': [[True,False],\n",
    "           [False],\n",
    "           [6]\n",
    "          ],\n",
    "}\n",
    "\n",
    "grid = {}\n",
    "for model in models.keys():\n",
    "    grid[model] = list(it.product(*parameters_values[model]))\n",
    "    for idx in range(len(grid[model])):\n",
    "        arguments = {}\n",
    "        for parameter_index, parameter_value in enumerate(grid[model][idx]):\n",
    "            arguments[parameters_names[model][parameter_index]] = parameter_value\n",
    "        grid[model][idx] = arguments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search: calulate the RMSE in validation splits for all parametrizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametrization 0 for Fold_0 starts at  2019-02-19 11:46:01.524171\n",
      "and finishes at  2019-02-19 11:46:04.987879  with RMSE  3.346740008113454 \n",
      "\n",
      "Parametrization 0 for Fold_1 starts at  2019-02-19 11:46:07.021854\n",
      "and finishes at  2019-02-19 11:46:10.397287  with RMSE  3.2397429897625982 \n",
      "\n",
      "Parametrization 1 for Fold_0 starts at  2019-02-19 11:46:12.339372\n",
      "and finishes at  2019-02-19 11:46:15.642852  with RMSE  3.3466836338440222 \n",
      "\n",
      "Parametrization 1 for Fold_1 starts at  2019-02-19 11:46:17.560394\n",
      "and finishes at  2019-02-19 11:46:20.739949  with RMSE  3.2412645166215657 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "RMSEs = {}\n",
    "for model in models.keys():\n",
    "    RMSEs[model] = pd.DataFrame(data=None,columns=parameters_names[model]+[\"Fold_\"+str(i) for i in \\\n",
    "                                                                           range(k)],[\"Mean\",\"Std\"])\n",
    "    for idx in range(len(grid[model])):\n",
    "        for fold in range(k):\n",
    "            # Define train and validation data for the ith fold\n",
    "            data_train = pd.concat([train_folds_list[i] for i in range(k) if i!=fold],axis=0)\n",
    "            data_val = train_folds_list[fold]        \n",
    "            x_train, y_train = data_train[features], data_train[target]\n",
    "            x_validation, y_validation = data_val[features], data_val[target]\n",
    "            # Train model\n",
    "            print(\"Parametrization \"+str(idx)+\" for Fold_\"+str(fold)+\" starts at \",\n",
    "                  datetime.datetime.now())\n",
    "            regressor = models[model](**grid[model][idx])\n",
    "            regressor.fit(x_train,y_train)\n",
    "            rmse_validation = rmse(regressor.predict(x_validation),y_validation)\n",
    "            print(\"and finishes at \",datetime.datetime.now(),\" with RMSE \",rmse_validation,\"\\n\")\n",
    "            # Add the RMSE to results\n",
    "            RMSEs[model].loc[idx,parameters_names[model]] = grid[model][idx]\n",
    "            RMSEs[model].loc[idx,\"Fold_\"+str(fold)] = rmse_validation\n",
    "        # Add the mean and std of the parametrization RMSE\n",
    "        RMSEs[model].loc[idx,\"Mean\"] = np.mean(RMSEs[model].loc[idx,[\"Fold_\"+str(i) for i in range(k)]])\n",
    "        RMSEs[model].loc[idx,\"Std\"] = np.std(RMSEs[model].loc[idx,[\"Fold_\"+str(i) for i in range(k)]])\n",
    "    # Sort the results by RMSE mean\n",
    "    RMSEs[model] = RMSEs[model].loc[np.argsort(RMSEs[model][\"Mean\"]),:]\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the validation results in a *pickle* file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the results by RMSE mean\n",
    "RMSEs[model] = RMSEs[model].loc[np.argsort(RMSEs[model][\"Mean\"]),:]\n",
    "pickle.dump(RMSEs,open('Validations/Results_validation_LinearRegression.dat','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Train optimal model with all Train and create submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSEs = pd.read_pickle(\"Validations/Results_validation_LinearRegression.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fit_intercept</th>\n",
       "      <th>normalize</th>\n",
       "      <th>n_jobs</th>\n",
       "      <th>Fold_0</th>\n",
       "      <th>Fold_1</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34674</td>\n",
       "      <td>3.23974</td>\n",
       "      <td>3.29324</td>\n",
       "      <td>0.0534985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6</td>\n",
       "      <td>3.34668</td>\n",
       "      <td>3.24126</td>\n",
       "      <td>3.29397</td>\n",
       "      <td>0.0527096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  fit_intercept normalize n_jobs   Fold_0   Fold_1     Mean        Std\n",
       "0          True     False      6  3.34674  3.23974  3.29324  0.0534985\n",
       "1         False     False      6  3.34668  3.24126  3.29397  0.0527096"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSEs[\"LR\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submission_LinearRegression_parametrization#.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all chosen parametrizations with all Train data. *Note:* We will use 1 parametrization with lowest mean RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametrization 0 with all Train starts at  2019-02-19 11:46:20.995786\n",
      "and finishes at  2019-02-19 11:46:25.606031 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = \"LR\"\n",
    "idx = RMSEs[model].index[0]\n",
    "# Define train data\n",
    "x_train, y_train = train[features], train[target]\n",
    "# Train model for the chosen parametrizations\n",
    "print(\"Parametrization \"+str(idx)+\" with all Train starts at \",datetime.datetime.now())\n",
    "regressor = models[model](**grid[model][idx])\n",
    "regressor.fit(x_train,y_train)\n",
    "print(\"and finishes at \",datetime.datetime.now(),\"\\n\")\n",
    "# Save model\n",
    "pickle.dump(regressor,open('Models/Model_LinearRegression_parametrization'+str(idx)+'.dat','wb'))\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Test data and create *.csv* file for submitting to Kaggle for all chosen parametrizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order of card_id in submission.csv OK? True\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('Data/sample_submission.csv')\n",
    "print(\"Order of card_id in submission.csv OK?\",np.mean(submission[\"card_id\"].values==test[\"card_id\"].\\\n",
    "                                                       values)==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = RMSEs[model].index[0]\n",
    "x_test = test[features]\n",
    "regressor = pickle.load(open('Models/Model_LinearRegression_parametrization'+str(idx)+'.dat','rb'))\n",
    "submission[\"target\"] = regressor.predict(x_test)\n",
    "submission.to_csv('Submissions/Submission_LinearRegression_parametrization'+str(idx)+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### submission_LinearRegression_parametrization1_wo_mean_encoding.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try doing feature selection, excluding the mean encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_wo_mean_encoding = [col for col in features if col not in features_mean_encoding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train all chosen parametrizations with all Train data. *Note:* We will use 1 parametrization with lowest mean RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "InteractiveShell.ast_node_interactivity = 'none'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametrization 0 with all Train starts at  2019-02-19 11:46:27.730803\n",
      "and finishes at  2019-02-19 11:46:32.460956 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = \"LR\"\n",
    "idx = RMSEs[model].index[0]\n",
    "# Define train data\n",
    "x_train, y_train = train[features_wo_mean_encoding], train[target]\n",
    "# Train model for all chosen parametrizations\n",
    "print(\"Parametrization \"+str(idx)+\" with all Train starts at \",datetime.datetime.now())\n",
    "regressor = models[model](**grid[model][idx])\n",
    "regressor.fit(x_train,y_train)\n",
    "print(\"and finishes at \",datetime.datetime.now(),\"\\n\")\n",
    "# Save model\n",
    "pickle.dump(regressor,open('Models/Model_LinearRegression_parametrization'+str(idx)+\\\n",
    "                           '_wo_mean_encoding.dat','wb'))\n",
    "\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict Test data and create *.csv* file for submitting to Kaggle for all chosen parametrizations without mean encoded features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Order of card_id in submission.csv OK? True\n"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('Data/sample_submission.csv')\n",
    "print(\"Order of card_id in submission.csv OK?\",np.mean(submission[\"card_id\"].values==test[\"card_id\"].\\\n",
    "                                                       values)==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = RMSEs[model].index[0]\n",
    "x_test = test[features_wo_mean_encoding]\n",
    "regressor = pickle.load(open('Models/Model_LinearRegression_parametrization'+str(idx)+\\\n",
    "                             '_wo_mean_encoding.dat','rb'))\n",
    "submission[\"target\"] = regressor.predict(x_test)\n",
    "submission.to_csv('Submissions/Submission_LinearRegression_parametrization'+str(idx)+\\\n",
    "                  '_wo_mean_encoding.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
